开启命令行的时候，在命令行输入：
scrapy crawl unsi -o xxx.csv
输出的文件名称可以随意制定xxx，推荐使用csv格式
爬虫需要python环境和scrapy包，没有的话可以通过pip install scrapy/conda install scrapy进行安装

如果按住shift 同时点击鼠标右键，没有powershell 的相关选项，可以在文件夹的地址栏输入cmd，然后敲回车，也可以输入执行爬虫的命令